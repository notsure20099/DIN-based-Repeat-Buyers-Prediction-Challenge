{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 用户行为，使用format1进行加载\n",
    "# 加载全量样本\n",
    "\"\"\"\n",
    "user_log = pd.read_csv('./data_format1/user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('./data_format1/user_info_format1.csv')\n",
    "train_data1 = pd.read_csv('./data_format1/train_format1.csv')\n",
    "submission = pd.read_csv('./data_format1/test_format1.csv')\n",
    "train_data = pd.read_csv('./data_format2/train_format2.csv')\n",
    "\"\"\"\n",
    "\n",
    "# 加载小样本\n",
    "user_log = pd.read_csv('sample_user_log.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('sample_user_info.csv')\n",
    "train_data1 = pd.read_csv('train.csv')\n",
    "submission = pd.read_csv('test.csv')\n",
    "train_data = pd.read_csv('train_format2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1['origin'] = 'train'\n",
    "submission['origin'] = 'test'\n",
    "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用merchant_id（原列名seller_id）\n",
    "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\n",
    "\n",
    "# 格式化\n",
    "user_log['user_id'] = user_log['user_id'].astype('int32')\n",
    "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\n",
    "user_log['item_id'] = user_log['item_id'].astype('int32')\n",
    "user_log['cat_id'] = user_log['cat_id'].astype('int32')\n",
    "user_log['brand_id'].fillna(0, inplace=True)\n",
    "user_log['brand_id'] = user_log['brand_id'].astype('int32')\n",
    "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对离散特征做LabelEncoder\n",
    "lbe_merchant_id=LabelEncoder()\n",
    "lbe_merchant_id.fit(np.r_[0,user_log['merchant_id'].values])\n",
    "user_log['merchant_id']=lbe_merchant_id.transform(user_log['merchant_id'])\n",
    "matrix['merchant_id']=lbe_merchant_id.transform(matrix['merchant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe_user_id=LabelEncoder()\n",
    "user_log['user_id']=lbe_user_id.fit_transform(user_log['user_id'])\n",
    "user_info['user_id']=lbe_user_id.transform(user_info['user_id'])\n",
    "matrix['user_id']=lbe_user_id.transform(matrix['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe_item_id=LabelEncoder()\n",
    "user_log['item_id']=lbe_item_id.fit_transform(user_log['item_id'])\n",
    "\n",
    "lbe_cat_id=LabelEncoder()\n",
    "user_log['cat_id']=lbe_cat_id.fit_transform(user_log['cat_id'])\n",
    "\n",
    "lbe_brand_id=LabelEncoder()\n",
    "user_log['brand_id']=lbe_brand_id.fit_transform(user_log['brand_id'])\n",
    "\n",
    "user_log['merchant_id'].max(),user_log['user_id'].max()\n",
    "matrix = matrix.merge(user_info, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\n",
    "matrix['age_range'].fillna(0, inplace=True)\n",
    "\n",
    "# 0:female, 1:male, 2:unknown\n",
    "matrix['gender'].fillna(2, inplace=True)\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
    "del user_info, train_data1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User特征处理\n",
    "groups = user_log.groupby(['user_id'])\n",
    "\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "#temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 时间间隔特征 u6 按照小时\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "\n",
    "# 统计action_type为0，1，2，3的个数（原始操作，没有补0）\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User特征处理\n",
    "groups = user_log.groupby(['user_id'])\n",
    "\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 商家特征处理\n",
    "groups = user_log.groupby(['merchant_id'])\n",
    "\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 统计商家被交互的action_type 唯一值\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照user_id, merchant_id分组\n",
    "groups = user_log.groupby(['user_id', 'merchant_id'])\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "\n",
    "# print(temp)\n",
    "# print('-'*100)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "\n",
    "#商家购买点击比\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "\n",
    "#不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "matrix.fillna(0, inplace=True)\n",
    "\n",
    "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe_action_type={0:1,1:2,2:3,3:4}\n",
    "user_log['action_type']=user_log['action_type'].map(lbe_action_type)\n",
    "\n",
    "# 用户行为sequence\n",
    "# 把user_log里同user的这些数据合并成一个list\n",
    "temp=pd.DataFrame(user_log.groupby('user_id')['merchant_id','action_type'].agg(lambda x:list(x)))\n",
    "\n",
    "# 列名称改成hist_merchant_id 和 hist_action_type \n",
    "temp.columns=['hist_merchant_id','hist_action_type']\n",
    "matrix = matrix.merge(temp, on=['user_id'], how='left') #统计时间间隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>prob</th>\n",
       "      <th>u1_x</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>u5</th>\n",
       "      <th>...</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>age_6</th>\n",
       "      <th>age_7</th>\n",
       "      <th>age_8</th>\n",
       "      <th>g_0</th>\n",
       "      <th>g_1</th>\n",
       "      <th>g_2</th>\n",
       "      <th>hist_merchant_id</th>\n",
       "      <th>hist_action_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16497</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[3735, 1203, 3490, 2968, 3510, 3510, 3388, 610...</td>\n",
       "      <td>[1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365</td>\n",
       "      <td>198</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1867, 3891, 141, 420, 3891, 420, 141, 1867, 1...</td>\n",
       "      <td>[4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10829</td>\n",
       "      <td>2278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[604, 1807, 2950, 604, 2101, 1807, 1807, 1807,...</td>\n",
       "      <td>[3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7974</td>\n",
       "      <td>951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234</td>\n",
       "      <td>105</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[644, 644, 951, 644, 644, 644, 3176, 951, 644,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14604</td>\n",
       "      <td>1892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186</td>\n",
       "      <td>106</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1885, 40, 172, 1727, 1727, 1892, 1727, 1727, ...</td>\n",
       "      <td>[1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 3, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id label origin  prob  u1_x   u2  u3  u4  u5  ...  age_4  \\\n",
       "0    16497         1203   0.0  train   0.0    46   29  12  16  16  ...      0   \n",
       "1     1950          946   0.0  train   0.0   365  198  46  46  45  ...      0   \n",
       "2    10829         2278   0.0  train   0.0    47   31  14  15  17  ...      0   \n",
       "3     7974          951   0.0  train   0.0   234  105  23  35  36  ...      0   \n",
       "4    14604         1892   0.0  train   0.0   186  106  34  40  39  ...      0   \n",
       "\n",
       "   age_5  age_6  age_7  age_8  g_0  g_1  g_2  \\\n",
       "0      0      0      0      0    0    1    0   \n",
       "1      0      0      0      0    1    0    0   \n",
       "2      0      0      0      0    1    0    0   \n",
       "3      0      0      0      0    0    1    0   \n",
       "4      0      0      1      0    1    0    0   \n",
       "\n",
       "                                    hist_merchant_id  \\\n",
       "0  [3735, 1203, 3490, 2968, 3510, 3510, 3388, 610...   \n",
       "1  [1867, 3891, 141, 420, 3891, 420, 141, 1867, 1...   \n",
       "2  [604, 1807, 2950, 604, 2101, 1807, 1807, 1807,...   \n",
       "3  [644, 644, 951, 644, 644, 644, 3176, 951, 644,...   \n",
       "4  [1885, 40, 172, 1727, 1727, 1892, 1727, 1727, ...   \n",
       "\n",
       "                                    hist_action_type  \n",
       "0  [1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, ...  \n",
       "4  [1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 3, 1, 1, ...  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模部分\n",
    "\n",
    "Step 1：给历史记录补零\n",
    "Step 2：分割测试数据\n",
    "Step 3：处理测试集的特征，根据特征值唯一值数量设置embedding维度，处理id和action为sparse feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 截取，补缺到定长M个\n",
    "# 在list后面补0\n",
    "M=500\n",
    "for feature in ['hist_merchant_id','hist_action_type']:\n",
    "    matrix[feature]=matrix[feature].map(lambda x:np.array(x+[0]*(M-len(x)))[:M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 使用DIN模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from deepctr.inputs import SparseFeat,VarLenSparseFeat,DenseFeat,get_feature_names\n",
    "from deepctr.models import DIN, DIEN, DSIN\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "14488\n",
      "merchant_id\n",
      "1856\n",
      "prob\n",
      "1\n",
      "u1_x\n",
      "825\n",
      "u2\n",
      "539\n",
      "u3\n",
      "124\n",
      "u4\n",
      "246\n",
      "u5\n",
      "237\n",
      "u6\n",
      "184\n",
      "u7\n",
      "772\n",
      "u8\n",
      "17\n",
      "u9\n",
      "79\n",
      "u10\n",
      "161\n",
      "u1_y\n",
      "825\n",
      "m1\n",
      "805\n",
      "m2\n",
      "406\n",
      "m3\n",
      "292\n",
      "m4\n",
      "56\n",
      "m5\n",
      "35\n",
      "m6\n",
      "757\n",
      "m7\n",
      "23\n",
      "m8\n",
      "208\n",
      "m9\n",
      "163\n",
      "m10\n",
      "1294\n",
      "um1\n",
      "170\n",
      "um2\n",
      "94\n",
      "um3\n",
      "22\n",
      "um4\n",
      "12\n",
      "um5\n",
      "166\n",
      "um6\n",
      "8\n",
      "um7\n",
      "10\n",
      "um8\n",
      "26\n",
      "um9\n",
      "184\n",
      "r1\n",
      "3265\n",
      "r2\n",
      "1413\n",
      "r3\n",
      "394\n",
      "age_0\n",
      "2\n",
      "age_2\n",
      "2\n",
      "age_3\n",
      "2\n",
      "age_4\n",
      "2\n",
      "age_5\n",
      "2\n",
      "age_6\n",
      "2\n",
      "age_7\n",
      "2\n",
      "age_8\n",
      "2\n",
      "g_0\n",
      "2\n",
      "g_1\n",
      "2\n",
      "g_2\n",
      "2\n",
      "action_type\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train_X['action_type']=3\n",
    "feature_columns = []\n",
    "for column in train_X.columns:\n",
    "    if column != 'hist_merchant_id' and column != 'hist_action_type':\n",
    "        print(column)\n",
    "        num = train_X[column].nunique()\n",
    "        if num > 10000:\n",
    "            dim = 10\n",
    "        else:\n",
    "            if num > 1000:\n",
    "                dim = 8\n",
    "            else:\n",
    "                dim = 4\n",
    "        print(num)\n",
    "        if column  == 'user_id':\n",
    "            feature_columns += [SparseFeat(column, 19111+1, embedding_dim=dim)]\n",
    "        elif column  == 'merchant_id':\n",
    "            feature_columns += [SparseFeat(column, 4994+1, embedding_dim=dim)]\n",
    "        elif column  == 'action_type':\n",
    "            feature_columns += [SparseFeat(column, 4+1, embedding_dim=dim)]\n",
    "        else:\n",
    "            feature_columns += [DenseFeat(column, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "varlenfeat_col = []\n",
    "varlenfeat_col += [SparseFeat('hist_merchant_id', 19111+1, embedding_dim=10, embedding_name='merchant_id')]\n",
    "varlenfeat_col += [SparseFeat('hist_action_type', 4+1, embedding_dim=4, embedding_name='action_type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sparsefeat in varlenfeat_col:\n",
    "    feature_columns += [VarLenSparseFeat(sparsefeat, maxlen=M)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_features=['merchant_id','action_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxlen为历史信息的长度，vocabulary_size为onehot的长度， +1对vocab size\n",
    "# feature_columns += [VarLenSparseFeat('hist_merchant_id', maxlen=M, length_name='merchant_id', weight_name='merchant_id'),\n",
    "#                    VarLenSparseFeat('hist_action_type', maxlen=M,  length_name='action_type', weight_name='action_type')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19112\n",
      "4994\n"
     ]
    }
   ],
   "source": [
    "print(len(user_log['user_id'].unique()))\n",
    "print(len(user_log['merchant_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='user_id', vocabulary_size=19112, embedding_dim=10, use_hash=False, dtype='int32', embedding_name='user_id', group_name='default_group'),\n",
       " SparseFeat(name='merchant_id', vocabulary_size=4995, embedding_dim=8, use_hash=False, dtype='int32', embedding_name='merchant_id', group_name='default_group'),\n",
       " DenseFeat(name='prob', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u1_x', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='u1_y', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='m10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='um9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='r1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='r2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='r3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_0', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='age_8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='g_0', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='g_1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='g_2', dimension=1, dtype='float32'),\n",
       " SparseFeat(name='action_type', vocabulary_size=5, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='action_type', group_name='default_group'),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_merchant_id', vocabulary_size=19112, embedding_dim=10, use_hash=False, dtype='int32', embedding_name='merchant_id', group_name='default_group'), maxlen=500, combiner='mean', length_name=None, weight_name=None, weight_norm=True),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_action_type', vocabulary_size=5, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='action_type', group_name='default_group'), maxlen=500, combiner='mean', length_name=None, weight_name=None, weight_norm=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_1/local_activation_unit_1/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_1/local_activation_unit_1/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_1/local_activation_unit_1/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_1/local_activation_unit_1/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "100%|███████████████████████████████| 17837/17837 [00:00<00:00, 1783616.65it/s]\n",
      "100%|███████████████████████████████| 17837/17837 [00:00<00:00, 1621452.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14269 samples, validate on 3568 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14269/14269 [==============================] - ETA: 2:15 - loss: 0.7230 - binary_crossentropy: 0.723 - ETA: 1:43 - loss: 0.8285 - binary_crossentropy: 0.828 - ETA: 1:31 - loss: 0.8235 - binary_crossentropy: 0.823 - ETA: 1:24 - loss: 0.8586 - binary_crossentropy: 0.858 - ETA: 1:18 - loss: 0.8857 - binary_crossentropy: 0.885 - ETA: 1:12 - loss: 0.8988 - binary_crossentropy: 0.898 - ETA: 1:08 - loss: 0.8909 - binary_crossentropy: 0.890 - ETA: 1:04 - loss: 0.9264 - binary_crossentropy: 0.926 - ETA: 1:00 - loss: 0.9406 - binary_crossentropy: 0.940 - ETA: 57s - loss: 0.9520 - binary_crossentropy: 0.952 - ETA: 54s - loss: 0.9558 - binary_crossentropy: 0.95 - ETA: 50s - loss: 0.9691 - binary_crossentropy: 0.96 - ETA: 47s - loss: 0.9594 - binary_crossentropy: 0.95 - ETA: 44s - loss: 0.9447 - binary_crossentropy: 0.94 - ETA: 40s - loss: 0.9379 - binary_crossentropy: 0.93 - ETA: 37s - loss: 0.9377 - binary_crossentropy: 0.93 - ETA: 34s - loss: 0.9180 - binary_crossentropy: 0.91 - ETA: 31s - loss: 0.9072 - binary_crossentropy: 0.90 - ETA: 27s - loss: 0.9054 - binary_crossentropy: 0.90 - ETA: 24s - loss: 0.9098 - binary_crossentropy: 0.90 - ETA: 21s - loss: 0.9024 - binary_crossentropy: 0.90 - ETA: 18s - loss: 0.9134 - binary_crossentropy: 0.91 - ETA: 15s - loss: 0.9143 - binary_crossentropy: 0.91 - ETA: 12s - loss: 0.9138 - binary_crossentropy: 0.91 - ETA: 8s - loss: 0.9074 - binary_crossentropy: 0.9074 - ETA: 5s - loss: 0.9154 - binary_crossentropy: 0.915 - ETA: 2s - loss: 0.9127 - binary_crossentropy: 0.912 - 92s 6ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 2/10\n",
      "14269/14269 [==============================] - ETA: 1:27 - loss: 0.7833 - binary_crossentropy: 0.783 - ETA: 1:27 - loss: 0.7833 - binary_crossentropy: 0.783 - ETA: 1:24 - loss: 0.8335 - binary_crossentropy: 0.833 - ETA: 1:18 - loss: 0.8360 - binary_crossentropy: 0.836 - ETA: 1:14 - loss: 0.8978 - binary_crossentropy: 0.897 - ETA: 1:10 - loss: 0.9138 - binary_crossentropy: 0.913 - ETA: 1:07 - loss: 0.9382 - binary_crossentropy: 0.938 - ETA: 1:04 - loss: 0.9189 - binary_crossentropy: 0.918 - ETA: 1:01 - loss: 0.9272 - binary_crossentropy: 0.927 - ETA: 58s - loss: 0.9038 - binary_crossentropy: 0.903 - ETA: 54s - loss: 0.8929 - binary_crossentropy: 0.89 - ETA: 51s - loss: 0.8887 - binary_crossentropy: 0.88 - ETA: 47s - loss: 0.8783 - binary_crossentropy: 0.87 - ETA: 44s - loss: 0.8715 - binary_crossentropy: 0.87 - ETA: 41s - loss: 0.8717 - binary_crossentropy: 0.87 - ETA: 38s - loss: 0.8925 - binary_crossentropy: 0.89 - ETA: 35s - loss: 0.8967 - binary_crossentropy: 0.89 - ETA: 31s - loss: 0.9005 - binary_crossentropy: 0.90 - ETA: 28s - loss: 0.9038 - binary_crossentropy: 0.90 - ETA: 25s - loss: 0.9113 - binary_crossentropy: 0.91 - ETA: 21s - loss: 0.9052 - binary_crossentropy: 0.90 - ETA: 18s - loss: 0.9038 - binary_crossentropy: 0.90 - ETA: 15s - loss: 0.9169 - binary_crossentropy: 0.91 - ETA: 12s - loss: 0.9214 - binary_crossentropy: 0.92 - ETA: 9s - loss: 0.9267 - binary_crossentropy: 0.9267 - ETA: 5s - loss: 0.9119 - binary_crossentropy: 0.911 - ETA: 2s - loss: 0.9172 - binary_crossentropy: 0.917 - 92s 6ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 3/10\n",
      "14269/14269 [==============================] - ETA: 1:23 - loss: 0.8737 - binary_crossentropy: 0.873 - ETA: 1:20 - loss: 0.7833 - binary_crossentropy: 0.783 - ETA: 1:17 - loss: 0.7632 - binary_crossentropy: 0.763 - ETA: 1:14 - loss: 0.8210 - binary_crossentropy: 0.821 - ETA: 1:11 - loss: 0.8436 - binary_crossentropy: 0.843 - ETA: 1:07 - loss: 0.8436 - binary_crossentropy: 0.843 - ETA: 1:04 - loss: 0.8565 - binary_crossentropy: 0.856 - ETA: 1:01 - loss: 0.8285 - binary_crossentropy: 0.828 - ETA: 58s - loss: 0.8235 - binary_crossentropy: 0.823 - ETA: 56s - loss: 0.8195 - binary_crossentropy: 0.81 - ETA: 52s - loss: 0.8353 - binary_crossentropy: 0.83 - ETA: 49s - loss: 0.8385 - binary_crossentropy: 0.83 - ETA: 46s - loss: 0.8621 - binary_crossentropy: 0.86 - ETA: 43s - loss: 0.8780 - binary_crossentropy: 0.87 - ETA: 40s - loss: 0.8757 - binary_crossentropy: 0.87 - ETA: 36s - loss: 0.8850 - binary_crossentropy: 0.88 - ETA: 33s - loss: 0.8967 - binary_crossentropy: 0.89 - ETA: 30s - loss: 0.8921 - binary_crossentropy: 0.89 - ETA: 27s - loss: 0.8975 - binary_crossentropy: 0.89 - ETA: 24s - loss: 0.8948 - binary_crossentropy: 0.89 - ETA: 21s - loss: 0.9081 - binary_crossentropy: 0.90 - ETA: 18s - loss: 0.9107 - binary_crossentropy: 0.91 - ETA: 15s - loss: 0.9090 - binary_crossentropy: 0.90 - ETA: 11s - loss: 0.9063 - binary_crossentropy: 0.90 - ETA: 8s - loss: 0.9062 - binary_crossentropy: 0.9062 - ETA: 5s - loss: 0.9003 - binary_crossentropy: 0.900 - ETA: 2s - loss: 0.9172 - binary_crossentropy: 0.917 - 90s 6ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 4/10\n",
      "14269/14269 [==============================] - ETA: 1:23 - loss: 1.3557 - binary_crossentropy: 1.355 - ETA: 1:20 - loss: 1.0996 - binary_crossentropy: 1.099 - ETA: 1:16 - loss: 1.0946 - binary_crossentropy: 1.094 - ETA: 1:13 - loss: 1.0921 - binary_crossentropy: 1.092 - ETA: 1:10 - loss: 1.0303 - binary_crossentropy: 1.030 - ETA: 1:07 - loss: 1.0444 - binary_crossentropy: 1.044 - ETA: 1:04 - loss: 1.0071 - binary_crossentropy: 1.007 - ETA: 1:01 - loss: 0.9603 - binary_crossentropy: 0.960 - ETA: 58s - loss: 0.9473 - binary_crossentropy: 0.947 - ETA: 54s - loss: 0.9369 - binary_crossentropy: 0.93 - ETA: 51s - loss: 0.9504 - binary_crossentropy: 0.95 - ETA: 48s - loss: 0.9515 - binary_crossentropy: 0.95 - ETA: 45s - loss: 0.9617 - binary_crossentropy: 0.96 - ETA: 42s - loss: 0.9425 - binary_crossentropy: 0.94 - ETA: 39s - loss: 0.9540 - binary_crossentropy: 0.95 - ETA: 36s - loss: 0.9528 - binary_crossentropy: 0.95 - ETA: 33s - loss: 0.9587 - binary_crossentropy: 0.95 - ETA: 30s - loss: 0.9423 - binary_crossentropy: 0.94 - ETA: 27s - loss: 0.9434 - binary_crossentropy: 0.94 - ETA: 24s - loss: 0.9324 - binary_crossentropy: 0.93 - ETA: 21s - loss: 0.9325 - binary_crossentropy: 0.93 - ETA: 18s - loss: 0.9312 - binary_crossentropy: 0.93 - ETA: 15s - loss: 0.9182 - binary_crossentropy: 0.91 - ETA: 11s - loss: 0.9289 - binary_crossentropy: 0.92 - ETA: 8s - loss: 0.9231 - binary_crossentropy: 0.9231 - ETA: 5s - loss: 0.9293 - binary_crossentropy: 0.929 - ETA: 2s - loss: 0.9150 - binary_crossentropy: 0.915 - 90s 6ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 5/10\n",
      "14269/14269 [==============================] - ETA: 1:24 - loss: 0.6628 - binary_crossentropy: 0.662 - ETA: 1:20 - loss: 0.7984 - binary_crossentropy: 0.798 - ETA: 1:17 - loss: 0.8235 - binary_crossentropy: 0.823 - ETA: 1:14 - loss: 0.8963 - binary_crossentropy: 0.896 - ETA: 1:11 - loss: 0.8978 - binary_crossentropy: 0.897 - ETA: 1:08 - loss: 0.9289 - binary_crossentropy: 0.928 - ETA: 1:04 - loss: 0.9468 - binary_crossentropy: 0.946 - ETA: 1:01 - loss: 0.9565 - binary_crossentropy: 0.956 - ETA: 58s - loss: 0.9674 - binary_crossentropy: 0.967 - ETA: 55s - loss: 0.9851 - binary_crossentropy: 0.98 - ETA: 52s - loss: 1.0024 - binary_crossentropy: 1.00 - ETA: 49s - loss: 0.9967 - binary_crossentropy: 0.99 - ETA: 45s - loss: 0.9617 - binary_crossentropy: 0.96 - ETA: 42s - loss: 0.9641 - binary_crossentropy: 0.96 - ETA: 39s - loss: 0.9560 - binary_crossentropy: 0.95 - ETA: 36s - loss: 0.9528 - binary_crossentropy: 0.95 - ETA: 33s - loss: 0.9251 - binary_crossentropy: 0.92 - ETA: 30s - loss: 0.9189 - binary_crossentropy: 0.91 - ETA: 27s - loss: 0.9070 - binary_crossentropy: 0.90 - ETA: 24s - loss: 0.9023 - binary_crossentropy: 0.90 - ETA: 21s - loss: 0.9067 - binary_crossentropy: 0.90 - ETA: 18s - loss: 0.9120 - binary_crossentropy: 0.91 - ETA: 15s - loss: 0.9182 - binary_crossentropy: 0.91 - ETA: 11s - loss: 0.9251 - binary_crossentropy: 0.92 - ETA: 8s - loss: 0.9110 - binary_crossentropy: 0.9110 - ETA: 5s - loss: 0.9050 - binary_crossentropy: 0.905 - ETA: 2s - loss: 0.9127 - binary_crossentropy: 0.912 - 90s 6ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "14269/14269 [==============================] - ETA: 1:26 - loss: 0.8436 - binary_crossentropy: 0.843 - ETA: 1:21 - loss: 0.7682 - binary_crossentropy: 0.768 - ETA: 1:17 - loss: 0.8737 - binary_crossentropy: 0.873 - ETA: 1:14 - loss: 0.9189 - binary_crossentropy: 0.918 - ETA: 1:11 - loss: 0.9339 - binary_crossentropy: 0.933 - ETA: 1:07 - loss: 0.9038 - binary_crossentropy: 0.903 - ETA: 1:04 - loss: 0.9038 - binary_crossentropy: 0.903 - ETA: 1:01 - loss: 0.8925 - binary_crossentropy: 0.892 - ETA: 58s - loss: 0.9105 - binary_crossentropy: 0.910 - ETA: 56s - loss: 0.9068 - binary_crossentropy: 0.90 - ETA: 53s - loss: 0.8983 - binary_crossentropy: 0.89 - ETA: 50s - loss: 0.8661 - binary_crossentropy: 0.86 - ETA: 47s - loss: 0.8737 - binary_crossentropy: 0.87 - ETA: 43s - loss: 0.8543 - binary_crossentropy: 0.85 - ETA: 40s - loss: 0.8576 - binary_crossentropy: 0.85 - ETA: 37s - loss: 0.8699 - binary_crossentropy: 0.86 - ETA: 34s - loss: 0.8719 - binary_crossentropy: 0.87 - ETA: 31s - loss: 0.8921 - binary_crossentropy: 0.89 - ETA: 27s - loss: 0.9006 - binary_crossentropy: 0.90 - ETA: 24s - loss: 0.8963 - binary_crossentropy: 0.89 - ETA: 21s - loss: 0.8995 - binary_crossentropy: 0.89 - ETA: 18s - loss: 0.9107 - binary_crossentropy: 0.91 - ETA: 15s - loss: 0.9130 - binary_crossentropy: 0.91 - ETA: 12s - loss: 0.9101 - binary_crossentropy: 0.91 - ETA: 9s - loss: 0.9098 - binary_crossentropy: 0.9098 - ETA: 5s - loss: 0.9200 - binary_crossentropy: 0.920 - ETA: 2s - loss: 0.9150 - binary_crossentropy: 0.915 - 91s 6ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 7/10\n",
      "14269/14269 [==============================] - ETA: 1:25 - loss: 0.9641 - binary_crossentropy: 0.964 - ETA: 1:21 - loss: 0.9339 - binary_crossentropy: 0.933 - ETA: 1:17 - loss: 0.9239 - binary_crossentropy: 0.923 - ETA: 1:14 - loss: 0.9415 - binary_crossentropy: 0.941 - ETA: 1:11 - loss: 0.9641 - binary_crossentropy: 0.964 - ETA: 1:08 - loss: 0.9390 - binary_crossentropy: 0.939 - ETA: 1:04 - loss: 0.9555 - binary_crossentropy: 0.955 - ETA: 1:01 - loss: 0.9302 - binary_crossentropy: 0.930 - ETA: 58s - loss: 0.9038 - binary_crossentropy: 0.903 - ETA: 56s - loss: 0.9068 - binary_crossentropy: 0.90 - ETA: 52s - loss: 0.9421 - binary_crossentropy: 0.94 - ETA: 49s - loss: 0.9314 - binary_crossentropy: 0.93 - ETA: 46s - loss: 0.9108 - binary_crossentropy: 0.91 - ETA: 43s - loss: 0.9382 - binary_crossentropy: 0.93 - ETA: 40s - loss: 0.9400 - binary_crossentropy: 0.94 - ETA: 37s - loss: 0.9170 - binary_crossentropy: 0.91 - ETA: 34s - loss: 0.9038 - binary_crossentropy: 0.90 - ETA: 30s - loss: 0.9122 - binary_crossentropy: 0.91 - ETA: 27s - loss: 0.9197 - binary_crossentropy: 0.91 - ETA: 24s - loss: 0.9098 - binary_crossentropy: 0.90 - ETA: 21s - loss: 0.9081 - binary_crossentropy: 0.90 - ETA: 18s - loss: 0.9175 - binary_crossentropy: 0.91 - ETA: 15s - loss: 0.9208 - binary_crossentropy: 0.92 - ETA: 12s - loss: 0.9251 - binary_crossentropy: 0.92 - ETA: 8s - loss: 0.9183 - binary_crossentropy: 0.9183 - ETA: 5s - loss: 0.9166 - binary_crossentropy: 0.916 - ETA: 2s - loss: 0.9150 - binary_crossentropy: 0.915 - 93s 6ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 8/10\n",
      "14269/14269 [==============================] - ETA: 1:24 - loss: 0.8436 - binary_crossentropy: 0.843 - ETA: 1:22 - loss: 0.8134 - binary_crossentropy: 0.813 - ETA: 1:18 - loss: 0.9440 - binary_crossentropy: 0.944 - ETA: 1:17 - loss: 0.9490 - binary_crossentropy: 0.949 - ETA: 1:14 - loss: 0.8677 - binary_crossentropy: 0.867 - ETA: 1:10 - loss: 0.8837 - binary_crossentropy: 0.883 - ETA: 1:07 - loss: 0.8694 - binary_crossentropy: 0.869 - ETA: 1:03 - loss: 0.8624 - binary_crossentropy: 0.862 - ETA: 1:00 - loss: 0.8737 - binary_crossentropy: 0.873 - ETA: 57s - loss: 0.8646 - binary_crossentropy: 0.864 - ETA: 53s - loss: 0.8792 - binary_crossentropy: 0.87 - ETA: 50s - loss: 0.9214 - binary_crossentropy: 0.92 - ETA: 47s - loss: 0.9177 - binary_crossentropy: 0.91 - ETA: 44s - loss: 0.9081 - binary_crossentropy: 0.90 - ETA: 41s - loss: 0.9118 - binary_crossentropy: 0.91 - ETA: 38s - loss: 0.8944 - binary_crossentropy: 0.89 - ETA: 34s - loss: 0.8914 - binary_crossentropy: 0.89 - ETA: 31s - loss: 0.8887 - binary_crossentropy: 0.88 - ETA: 28s - loss: 0.8879 - binary_crossentropy: 0.88 - ETA: 25s - loss: 0.8857 - binary_crossentropy: 0.88 - ETA: 22s - loss: 0.8809 - binary_crossentropy: 0.88 - ETA: 18s - loss: 0.8833 - binary_crossentropy: 0.88 - ETA: 15s - loss: 0.8868 - binary_crossentropy: 0.88 - ETA: 12s - loss: 0.8825 - binary_crossentropy: 0.88 - ETA: 9s - loss: 0.8930 - binary_crossentropy: 0.8930 - ETA: 5s - loss: 0.9003 - binary_crossentropy: 0.900 - ETA: 2s - loss: 0.9060 - binary_crossentropy: 0.906 - 93s 7ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 9/10\n",
      "14269/14269 [==============================] - ETA: 1:25 - loss: 0.9641 - binary_crossentropy: 0.964 - ETA: 1:24 - loss: 0.9490 - binary_crossentropy: 0.949 - ETA: 1:21 - loss: 0.9641 - binary_crossentropy: 0.964 - ETA: 1:17 - loss: 0.9565 - binary_crossentropy: 0.956 - ETA: 1:13 - loss: 0.9159 - binary_crossentropy: 0.915 - ETA: 1:10 - loss: 0.9239 - binary_crossentropy: 0.923 - ETA: 1:07 - loss: 0.8866 - binary_crossentropy: 0.886 - ETA: 1:04 - loss: 0.9452 - binary_crossentropy: 0.945 - ETA: 1:01 - loss: 0.9574 - binary_crossentropy: 0.957 - ETA: 58s - loss: 0.9189 - binary_crossentropy: 0.918 - ETA: 55s - loss: 0.9011 - binary_crossentropy: 0.90 - ETA: 52s - loss: 0.8913 - binary_crossentropy: 0.89 - ETA: 49s - loss: 0.8899 - binary_crossentropy: 0.88 - ETA: 45s - loss: 0.8887 - binary_crossentropy: 0.88 - ETA: 42s - loss: 0.8958 - binary_crossentropy: 0.89 - ETA: 39s - loss: 0.8982 - binary_crossentropy: 0.89 - ETA: 35s - loss: 0.9056 - binary_crossentropy: 0.90 - ETA: 32s - loss: 0.9072 - binary_crossentropy: 0.90 - ETA: 29s - loss: 0.8990 - binary_crossentropy: 0.89 - ETA: 26s - loss: 0.8918 - binary_crossentropy: 0.89 - ETA: 22s - loss: 0.8966 - binary_crossentropy: 0.89 - ETA: 19s - loss: 0.9093 - binary_crossentropy: 0.90 - ETA: 16s - loss: 0.9064 - binary_crossentropy: 0.90 - ETA: 12s - loss: 0.9038 - binary_crossentropy: 0.90 - ETA: 9s - loss: 0.9086 - binary_crossentropy: 0.9086 - ETA: 6s - loss: 0.9119 - binary_crossentropy: 0.911 - ETA: 2s - loss: 0.9127 - binary_crossentropy: 0.912 - 97s 7ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n",
      "Epoch 10/10\n",
      "14269/14269 [==============================] - ETA: 1:25 - loss: 0.9641 - binary_crossentropy: 0.964 - ETA: 1:23 - loss: 1.0394 - binary_crossentropy: 1.039 - ETA: 1:21 - loss: 0.9138 - binary_crossentropy: 0.913 - ETA: 1:18 - loss: 0.8887 - binary_crossentropy: 0.888 - ETA: 1:16 - loss: 0.9159 - binary_crossentropy: 0.915 - ETA: 1:13 - loss: 0.9590 - binary_crossentropy: 0.959 - ETA: 1:09 - loss: 0.9641 - binary_crossentropy: 0.964 - ETA: 1:06 - loss: 0.9226 - binary_crossentropy: 0.922 - ETA: 1:03 - loss: 0.9239 - binary_crossentropy: 0.923 - ETA: 59s - loss: 0.9580 - binary_crossentropy: 0.958 - ETA: 56s - loss: 0.9285 - binary_crossentropy: 0.92 - ETA: 52s - loss: 0.9164 - binary_crossentropy: 0.91 - ETA: 49s - loss: 0.9177 - binary_crossentropy: 0.91 - ETA: 45s - loss: 0.9275 - binary_crossentropy: 0.92 - ETA: 42s - loss: 0.9259 - binary_crossentropy: 0.92 - ETA: 39s - loss: 0.9415 - binary_crossentropy: 0.94 - ETA: 35s - loss: 0.9392 - binary_crossentropy: 0.93 - ETA: 32s - loss: 0.9356 - binary_crossentropy: 0.93 - ETA: 28s - loss: 0.9339 - binary_crossentropy: 0.93 - ETA: 25s - loss: 0.9309 - binary_crossentropy: 0.93 - ETA: 22s - loss: 0.9440 - binary_crossentropy: 0.94 - ETA: 19s - loss: 0.9312 - binary_crossentropy: 0.93 - ETA: 15s - loss: 0.9274 - binary_crossentropy: 0.92 - ETA: 12s - loss: 0.9251 - binary_crossentropy: 0.92 - ETA: 9s - loss: 0.9159 - binary_crossentropy: 0.9159 - ETA: 6s - loss: 0.9050 - binary_crossentropy: 0.905 - ETA: 2s - loss: 0.9094 - binary_crossentropy: 0.909 - 95s 7ms/sample - loss: 0.9135 - binary_crossentropy: 0.9135 - val_loss: 0.9338 - val_binary_crossentropy: 0.9338\n"
     ]
    }
   ],
   "source": [
    "# 使用DIN模型\n",
    "model = DIN(dnn_feature_columns = feature_columns,\n",
    "            history_feature_list = hist_features, )\n",
    "\n",
    "# 使用Adam优化器，二分类的交叉熵\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['binary_crossentropy'])\n",
    "\n",
    "# 组装train_model_input，得到feature names，将train_X转换为字典格式\n",
    "feature_names=list(train_X.columns)\n",
    "train_model_input = {name:train_X[name].values for name in feature_names}\n",
    "\n",
    "# histroy输入必须是二维数组\n",
    "from tqdm import tqdm\n",
    "for fea in ['hist_merchant_id','hist_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(train_model_input[fea]):\n",
    "        l.append(i)\n",
    "    train_model_input[fea]=np.array(l)\n",
    "train_y = train_y.astype(np.float32)\n",
    "history = model.fit(train_model_input, train_y, verbose=True, epochs=10, validation_split=0.2,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "DeepCTR version 0.7.5 detected. Your version is 0.7.4.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.7.5\n"
     ]
    }
   ],
   "source": [
    "# 转换test__model_input\n",
    "test_data['action_type']=3\n",
    "test_model_input = {name:test_data[name].values for name in feature_names}\n",
    "from tqdm import tqdm\n",
    "for fea in ['hist_merchant_id','hist_action_type']:\n",
    "    l = []\n",
    "    for i in tqdm(test_model_input[fea]):\n",
    "        l.append(i)\n",
    "    test_model_input[fea]=np.array(l)\n",
    "\n",
    "# 得到预测结果\n",
    "prob = model.predict(test_model_input)\n",
    "submission['prob'] = prob\n",
    "submission.drop(['origin'], axis=1, inplace=True)\n",
    "submission.to_csv('prediction.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
